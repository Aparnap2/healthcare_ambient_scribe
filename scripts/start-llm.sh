#!/bin/bash
# Start Ollama with the qwen2.5-coder:3b model
# Usage: ./scripts/start-llm.sh

set -e

echo "üöÄ Starting Ollama..."
docker run -d \
  --name healthcare-scribe-ollama \
  -p 11434:11434 \
  -v ollama_data:/root/.ollama \
  ollama/ollama

echo "‚è≥ Waiting for Ollama to be ready..."
sleep 5

echo "üì¶ Pulling qwen2.5-coder:3b model (this may take a few minutes)..."
docker exec healthcare-scribe-ollama ollama pull qwen2.5-coder:3b

echo ""
echo "‚úÖ Ollama started!"
echo "  - API: localhost:11434"
echo "  - Model: qwen2.5-coder:3b"
